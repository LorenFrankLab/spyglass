{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8dbc3f",
   "metadata": {},
   "source": [
    "## Position V2 - Streamlined Pose Estimation Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daae738",
   "metadata": {},
   "source": [
    "### Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e764667",
   "metadata": {},
   "source": [
    "_Developer Note:_ if you may make a PR in the future, be sure to copy this\n",
    "notebook, and use the `gitignore` prefix `temp` to avoid future conflicts.\n",
    "\n",
    "This is one notebook in a multi-part series on Spyglass.\n",
    "\n",
    "- To set up your Spyglass environment and database, see\n",
    "  [the Setup notebook](./00_Setup.ipynb)\n",
    "- For additional info on DataJoint syntax, including table definitions and\n",
    "  inserts, see\n",
    "  [the Insert Data notebook](./02_Insert_Data.ipynb)\n",
    "- For the legacy V1 DLC pipeline, see\n",
    "  [the DLC notebook](./21_DLC.ipynb)\n",
    "\n",
    "**Position V2** is designed to expand the functionality of the V1 pipeline\n",
    "while simplifying the number of tables. The V2 pipeline:\n",
    "\n",
    "- **Reduces complexity**: 4 main tables instead of 10+\n",
    "- **Multi-tool support**: Works with DLC, SLEAP, and any ndx-pose compatible tool\n",
    "- **Flexible workflows**: Import pre-trained models or train new ones\n",
    "- **NWB-native storage**: Uses ndx-pose extension for standardized data\n",
    "- **Simplified processing**: Single PoseV2 table handles all position processing\n",
    "\n",
    "This tutorial will walk through:\n",
    "\n",
    "- Importing a trained model (DLC or ndx-pose)\n",
    "- Running pose estimation on videos\n",
    "- Processing pose data (orientation, centroid, smoothing)\n",
    "- Retrieving and visualizing results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09561450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-03 12:10:47,394][INFO]: DataJoint is configured from /home/cb/wrk/spyglass/pv2/dj_local_conf.json\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"454pt\" height=\"449pt\" viewBox=\"0.00 0.00 453.97 448.64\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 444.64)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-444.64 449.97,-444.64 449.97,4 -4,4\"/>\n",
       "<!-- estim.PoseSelection -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>estim.PoseSelection</title>\n",
       "<g id=\"a_node1\"><a xlink:title=\"→ estim.PoseEstim\r→ estim.PoseParams\r\">\n",
       "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"344.5,-96.48 219,-96.48 219,-61.92 344.5,-61.92 344.5,-96.48\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.75\" y=\"-74.92\" font-family=\"arial\" font-size=\"12.00\" fill=\"darkgreen\">estim.PoseSelection</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- estim.PoseV2 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>estim.PoseV2</title>\n",
       "<g id=\"a_node11\"><a xlink:title=\"→ estim.PoseSelection\r------------------------------\r→ train.AnalysisNwbfile\rorient_obj_id        \rcentroid_obj_id      \rvelocity_obj_id      \rsmoothed_pose_id     \r\">\n",
       "<ellipse fill=\"#ff0000\" fill-opacity=\"0.125490\" stroke=\"#ff0000\" stroke-opacity=\"0.125490\" cx=\"281.75\" cy=\"-12.96\" rx=\"12.96\" ry=\"12.96\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.75\" y=\"-8.69\" font-family=\"arial\" font-size=\"12.00\" fill=\"#7f0000\" fill-opacity=\"0.627451\">estim.PoseV2</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- estim.PoseSelection&#45;&gt;estim.PoseV2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>estim.PoseSelection-&gt;estim.PoseV2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"2\" stroke-opacity=\"0.250980\" d=\"M281.75,-61.66C281.75,-50.36 281.75,-35.66 281.75,-25.58\"/>\n",
       "</g>\n",
       "<!-- train.Skeleton -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>train.Skeleton</title>\n",
       "<g id=\"a_node2\"><a xlink:title=\"skeleton_id          \r------------------------------\rbodyparts            \redges=null           \rhash=null            \r\">\n",
       "<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"none\" points=\"100.75,-440.64 24.75,-440.64 24.75,-406.08 100.75,-406.08 100.75,-440.64\"/>\n",
       "<text text-anchor=\"start\" x=\"32.75\" y=\"-420.86\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"10.00\">train.Skeleton</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- train.ModelParams -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>train.ModelParams</title>\n",
       "<g id=\"a_node8\"><a xlink:title=\"model_params_id      \rtool                 \r------------------------------\rparams               \r→ [nullable] train.Skeleton\rparams_hash          \rUNIQUE INDEX (tool, params_hash)\r\">\n",
       "<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"none\" points=\"111.62,-370.08 13.88,-370.08 13.88,-335.52 111.62,-335.52 111.62,-370.08\"/>\n",
       "<text text-anchor=\"start\" x=\"21.88\" y=\"-350.3\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"10.00\">train.ModelParams</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- train.Skeleton&#45;&gt;train.ModelParams -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>train.Skeleton-&gt;train.ModelParams</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-dasharray=\"5,2\" stroke-opacity=\"0.250980\" d=\"M62.75,-406.11C62.75,-395.18 62.75,-380.84 62.75,-369.93\"/>\n",
       "</g>\n",
       "<!-- video.VidFileGroup.Calibration -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>video.VidFileGroup.Calibration</title>\n",
       "<g id=\"a_node3\"><a xlink:title=\"→ video.VidFileGroup\rcalibration_id       \r------------------------------\rpath                 \r\">\n",
       "<polygon fill=\"none\" stroke=\"none\" points=\"291.75,-292.24 143.75,-292.24 143.75,-272.24 291.75,-272.24 291.75,-292.24\"/>\n",
       "<text text-anchor=\"start\" x=\"151.75\" y=\"-279.74\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"10.00\">video.VidFileGroup.Calibration</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- train.Model -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>train.Model</title>\n",
       "<g id=\"a_node4\"><a xlink:title=\"model_id             \r------------------------------\r→ train.ModelSelection\r→ [nullable] train.AnalysisNwbfile\rmodel_path           \r\">\n",
       "<ellipse fill=\"#ff0000\" fill-opacity=\"0.125490\" stroke=\"#ff0000\" stroke-opacity=\"0.125490\" cx=\"226.75\" cy=\"-216\" rx=\"12.96\" ry=\"12.96\"/>\n",
       "<text text-anchor=\"start\" x=\"197.12\" y=\"-212.72\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"#7f0000\" fill-opacity=\"0.627451\">train.Model</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- estim.PoseEstim -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>estim.PoseEstim</title>\n",
       "<g id=\"a_node12\"><a xlink:title=\"→ train.Model\r→ video.VidFileGroup\r------------------------------\r→ [nullable] train.AnalysisNwbfile\r\">\n",
       "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"394.38,-167.04 289.12,-167.04 289.12,-132.48 394.38,-132.48 394.38,-167.04\"/>\n",
       "<text text-anchor=\"middle\" x=\"341.75\" y=\"-145.48\" font-family=\"arial\" font-size=\"12.00\" fill=\"darkgreen\">estim.PoseEstim</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- train.Model&#45;&gt;estim.PoseEstim -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>train.Model-&gt;estim.PoseEstim</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M237.36,-209.07C254.16,-199.69 287.46,-181.09 311.95,-167.41\"/>\n",
       "</g>\n",
       "<!-- video.VidFileGroup.File -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>video.VidFileGroup.File</title>\n",
       "<g id=\"a_node5\"><a xlink:title=\"→ video.VidFileGroup\r→ video.VideoFile\r\">\n",
       "<polygon fill=\"none\" stroke=\"none\" points=\"427.38,-292.24 310.12,-292.24 310.12,-272.24 427.38,-272.24 427.38,-292.24\"/>\n",
       "<text text-anchor=\"middle\" x=\"368.75\" y=\"-278.74\" font-family=\"arial\" font-size=\"10.00\">video.VidFileGroup.File</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- train.ModelSelection -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>train.ModelSelection</title>\n",
       "<g id=\"a_node6\"><a xlink:title=\"→ train.ModelParams\r→ video.VidFileGroup\r------------------------------\rparent_id=null       \r\">\n",
       "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"125.5,-299.52 0,-299.52 0,-264.96 125.5,-264.96 125.5,-299.52\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.75\" y=\"-277.97\" font-family=\"arial\" font-size=\"12.00\" fill=\"darkgreen\">train.ModelSelection</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- train.ModelSelection&#45;&gt;train.Model -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>train.ModelSelection-&gt;train.Model</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-dasharray=\"5,2\" stroke-opacity=\"0.250980\" d=\"M105.41,-264.53C142.23,-250.11 192.93,-230.25 215.33,-221.47\"/>\n",
       "</g>\n",
       "<!-- train.BodyPart -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>train.BodyPart</title>\n",
       "<g id=\"a_node7\"><a xlink:title=\"bodypart             \r\">\n",
       "<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"none\" points=\"196.88,-440.64 118.62,-440.64 118.62,-406.08 196.88,-406.08 196.88,-440.64\"/>\n",
       "<text text-anchor=\"start\" x=\"126.62\" y=\"-420.86\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"10.00\">train.BodyPart</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- train.ModelParams&#45;&gt;train.ModelSelection -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>train.ModelParams-&gt;train.ModelSelection</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M62.75,-335.55C62.75,-324.78 62.75,-310.69 62.75,-299.85\"/>\n",
       "</g>\n",
       "<!-- estim.PoseParams -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>estim.PoseParams</title>\n",
       "<g id=\"a_node9\"><a xlink:title=\"pose_params          \r------------------------------\rorient               \rcentroid             \rsmoothing            \r\">\n",
       "<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"none\" points=\"271.38,-167.04 172.12,-167.04 172.12,-132.48 271.38,-132.48 271.38,-167.04\"/>\n",
       "<text text-anchor=\"start\" x=\"180.12\" y=\"-147.26\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"10.00\">estim.PoseParams</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- estim.PoseParams&#45;&gt;estim.PoseSelection -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>estim.PoseParams-&gt;estim.PoseSelection</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M235.97,-132.51C245.4,-121.74 257.73,-107.65 267.22,-96.81\"/>\n",
       "</g>\n",
       "<!-- video.VidFileGroup -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>video.VidFileGroup</title>\n",
       "<g id=\"a_node10\"><a xlink:title=\"vid_group_id         \r------------------------------\rdescription          \r\">\n",
       "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"352.12,-370.08 233.38,-370.08 233.38,-335.52 352.12,-335.52 352.12,-370.08\"/>\n",
       "<text text-anchor=\"start\" x=\"241.38\" y=\"-349.53\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">video.VidFileGroup</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- video.VidFileGroup&#45;&gt;video.VidFileGroup.Calibration -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>video.VidFileGroup-&gt;video.VidFileGroup.Calibration</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M274.59,-335.2C259.68,-321.57 239.15,-302.8 227.28,-291.95\"/>\n",
       "</g>\n",
       "<!-- video.VidFileGroup&#45;&gt;video.VidFileGroup.File -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>video.VidFileGroup-&gt;video.VidFileGroup.File</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M311.15,-335.2C326.26,-321.57 347.07,-302.8 359.1,-291.95\"/>\n",
       "</g>\n",
       "<!-- video.VidFileGroup&#45;&gt;train.ModelSelection -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>video.VidFileGroup-&gt;train.ModelSelection</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M236.49,-335.03C200.71,-324.36 154.57,-310.61 118.83,-299.96\"/>\n",
       "</g>\n",
       "<!-- video.VidFileGroup&#45;&gt;estim.PoseEstim -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>video.VidFileGroup-&gt;estim.PoseEstim</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M352.29,-346.13C382.89,-339.85 417.67,-326.75 436.75,-299.52 469.55,-252.72 404.14,-195.16 366.21,-167.35\"/>\n",
       "</g>\n",
       "<!-- estim.PoseEstim&#45;&gt;estim.PoseSelection -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>estim.PoseEstim-&gt;estim.PoseSelection</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-width=\"0.75\" stroke-opacity=\"0.250980\" d=\"M327.23,-132.16C317.79,-121.38 305.55,-107.39 296.14,-96.64\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<datajoint.diagram.Diagram at 0x796f76e429b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datajoint as dj \n",
    "\n",
    "dj.config.load('../dj_local_conf.json') # TODO: REMOVE BEFORE MERGE\n",
    "\n",
    "from spyglass.position.v2 import video, train, estim\n",
    "\n",
    "dj.Diagram(video) + dj.Diagram(train) + dj.Diagram(estim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b7d0c",
   "metadata": {},
   "source": [
    "### Table of Contents<a id='TableOfContents'></a>\n",
    "\n",
    "- [`BodyParts`](#BodyParts)\n",
    "- [`Model`](#Model)\n",
    "- [`PoseEstim`](#PoseEstim)\n",
    "- [`PoseParams`](#PoseParams)\n",
    "- [`PoseV2`](#PoseV2)\n",
    "- [`Fetching Data`](#FetchData)\n",
    "- [`Visualization`](#Visualization)\n",
    "- [`V1 vs V2 Comparison`](#Comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b6df3",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a7d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ec39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from spyglass.position.v2 import (\n",
    "    BodyPart,\n",
    "    Model,\n",
    "    PoseEstim,\n",
    "    PoseParams,\n",
    "    PoseV2,\n",
    "    Skeleton,\n",
    ")\n",
    "\n",
    "# ignore datajoint+jupyter async warnings\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ResourceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75d0ac",
   "metadata": {},
   "source": [
    "## Path 1: Import Existing Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679b26f",
   "metadata": {},
   "source": [
    "### [Model](#TableOfContents) <a id=\"Model\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0205af29",
   "metadata": {},
   "source": [
    "For most experiments, you'll start with an existing trained model rather than\n",
    "training from scratch. Position V2 supports different import methods:\n",
    "\n",
    "1. **DLC config.yaml**: Import models trained with DeepLabCut\n",
    "2. **NWB file**: Import models from any ndx-pose compatible tool\n",
    "3. **SLEAP config**: `NotYetImplemented`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0689d33",
   "metadata": {},
   "source": [
    "Let's start by looking at the Model table:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cf19f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Table{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Table th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Table td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Table tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        .Table tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    <b></b>\n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Table\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">model_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">model_params_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">tool</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">vid_group_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">analysis_file_name</p>\n",
       "                            <span class=\"djtooltiptext\">name of the file</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">model_path</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr>  </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 0</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*model_id    model_params_i tool     vid_group_id   analysis_file_ model_path    \n",
       "+----------+ +------------+ +------+ +------------+ +------------+ +------------+\n",
       "\n",
       " (Total: 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e8ea8",
   "metadata": {},
   "source": [
    "#### Import from DeepLabCut Project\n",
    "\n",
    "If you have a DeepLabCut model already trained, you can import it by changing\n",
    "the following to the path to your `config.yaml`. If not, use the following\n",
    "codeblock to download and set up an example project.\n",
    "\n",
    "```bash\n",
    "cd /your/desired/path\n",
    "git clone https://github.com/DeepLabCut/DeepLabCut/\n",
    "python ./DeepLabCut/examples/testscript.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1309cdc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Table.insert() got an unexpected keyword argument 'raise_on_duplicate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Import the model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m----> 8\u001b[0m     model_key \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImported model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/wrk/spyglass/pv2/src/spyglass/position/v2/train.py:1463\u001b[0m, in \u001b[0;36mimport_model\u001b[0;34m(self, model_path, tool, skeleton_id, model_params_id, model_id, model_name, **kwargs)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimport_model\u001b[39m(\n\u001b[1;32m   1432\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1433\u001b[0m     model_path: Union[Path, \u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1440\u001b[0m ):\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Import an existing trained model into the database.\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m \n\u001b[1;32m   1443\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;124;03m    model_path : Union[Path, str]\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03m        Path to the model file or configuration (e.g., DLC .yml file or\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;124;03m        ndx-pose NWB file)\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;124;03m    tool : str, optional\u001b[39;00m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;124;03m        Tool used to train the model. If None, auto-detect from file type.\u001b[39;00m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;124;03m        Options: \"DLC\", \"ndx-pose\"\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m    skeleton_id : Union[str, None], optional\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;124;03m        Skeleton ID to associate with the model. If None, auto-generate\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;124;03m        default\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;124;03m    model_params_id : Union[str, None], optional\u001b[39;00m\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;124;03m        Model parameters ID to associate with the model. If None,\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;124;03m        auto-generate\u001b[39;00m\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;124;03m    model_id : Union[str, None], optional\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;124;03m        Model ID to assign. If None, auto-generate\u001b[39;00m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;124;03m    model_name : Union[str, None], optional\u001b[39;00m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;124;03m        For NWB files with multiple models, specify which model to import.\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;124;03m        Required if NWB contains multiple PoseEstimation objects.\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m    **kwargs\u001b[39;00m\n\u001b[0;32m-> 1463\u001b[0m \u001b[38;5;124;03m        Additional parameters for specific tools. Common parameters:\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;124;03m        - nwb_file_name: Parent NWB file name for linking\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m \n\u001b[1;32m   1466\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;124;03m    dict\u001b[39;00m\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;124;03m        Primary key for the created Model entry\u001b[39;00m\n\u001b[1;32m   1470\u001b[0m \n\u001b[1;32m   1471\u001b[0m \u001b[38;5;124;03m    Raises\u001b[39;00m\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;124;03m    ------\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;124;03m    FileNotFoundError\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;124;03m        If the model path does not exist.\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;124;03m    ValueError\u001b[39;00m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;124;03m        If file type cannot be determined or multiple models found without\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;124;03m        model_name specified.\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;124;03m    NotImplementedError\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03m        If the tool is not supported or import not implemented.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1481\u001b[0m     \u001b[38;5;66;03m# Validate model path\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m Path(model_path)\n",
      "File \u001b[0;32m~/wrk/spyglass/pv2/src/spyglass/position/v2/train.py:1483\u001b[0m, in \u001b[0;36m_import_dlc_model\u001b[0;34m(self, model_path, **kwargs)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;66;03m# Validate model path\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m model_path \u001b[38;5;241m=\u001b[39m Path(model_path)\n\u001b[0;32m-> 1483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m   1484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel path does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1486\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m   1488\u001b[0m         kwargs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m     )\n\u001b[1;32m   1494\u001b[0m )\n",
      "File \u001b[0;32m~/wrk/spyglass/pv2/src/spyglass/position/v2/train.py:595\u001b[0m, in \u001b[0;36minsert1\u001b[0;34m(self, key, accept_default, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minsert1\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, accept_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    589\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Insert model parameters into the database.\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m    1. Check if key is a dictionary\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m    2. Check if tool is supported\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m    3. Check if all required parameters are present, remove skipped\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m    4. Check if params already exist\u001b[39;00m\n\u001b[0;32m--> 595\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    597\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey must be a dictionary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pv2/lib/python3.10/site-packages/datajoint/table.py:349\u001b[0m, in \u001b[0;36mTable.insert1\u001b[0;34m(self, row, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minsert1\u001b[39m(\u001b[38;5;28mself\u001b[39m, row, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    343\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m    Insert one data record into the table. For ``kwargs``, see ``insert()``.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    :param row: a numpy record, a dict-like object, or an ordered sequence to be inserted\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m        as one row.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Table.insert() got an unexpected keyword argument 'raise_on_duplicate'"
     ]
    }
   ],
   "source": [
    "# Point to your DLC project config file\n",
    "dlc_path = Path.home() / \"DeepLabCut\"\n",
    "dlc_path = Path.home() / \"wrk\" / \"alt\" / \"DeepLabCut\" # TODO: REMOVE BEFORE MERGE\n",
    "config_path = dlc_path / \"examples\" / \"TEST-Alex-2025-09-08\" / \"config.yaml\"\n",
    "\n",
    "# Import the model\n",
    "if config_path.exists():\n",
    "    model_key = Model().import_model(config_path)\n",
    "    print(f\"Imported model: {model_key}\")\n",
    "else:\n",
    "    print(f\"Config not found at {config_path}\")\n",
    "    print(\"Adjust the path or run testscript.py to create example project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9018f70",
   "metadata": {},
   "source": [
    "The import process:\n",
    "\n",
    "1. Detects the latest trained model snapshot\n",
    "2. Extracts the skeleton (bodyparts and connections)\n",
    "3. Creates entries in Skeleton and ModelParams tables\n",
    "4. Stores model metadata in an NWB file\n",
    "5. Creates a Model entry for inference\n",
    "\n",
    "Let's verify the import:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16947a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model entry\n",
    "Model() & model_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14878f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the associated skeleton\n",
    "Skeleton() & model_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e068aa",
   "metadata": {},
   "source": [
    "#### Import from NWB File\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc766a88",
   "metadata": {},
   "source": [
    "If you have pose estimation data from DLC, SLEAP, or another tool stored in\n",
    "NWB format using ndx-pose, you can import it:\n",
    "\n",
    "```python\n",
    "nwb_path = \"/path/to/pose_estimation.nwb\"\n",
    "model_key = Model().import_model(nwb_path)\n",
    "```\n",
    "\n",
    "This is useful for:\n",
    "- Importing models from collaborators\n",
    "- Using models trained with SLEAP\n",
    "- Working with pre-processed data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a615ed48",
   "metadata": {},
   "source": [
    "### [PoseEstim](#TableOfContents) <a id=\"PoseEstim\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0fc61b",
   "metadata": {},
   "source": [
    "Now that we have a model, let's run pose estimation on a video.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d37078",
   "metadata": {},
   "source": [
    "#### Option A: Load existing DLC output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e37332",
   "metadata": {},
   "source": [
    "If you've already run DLC inference and have the output files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f846a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load existing DLC h5/csv files into NWB\n",
    "# dlc_output = \"/path/to/video_DLC_resnet50_project100000.h5\"\n",
    "# nwb_file = \"analysis_20250106.nwb\"\n",
    "#\n",
    "# PoseEstim.load_dlc_output(\n",
    "#     dlc_output_path=dlc_output,\n",
    "#     nwb_file_name=nwb_file\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7d7ff",
   "metadata": {},
   "source": [
    "#### Option B: Run inference with Spyglass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc863c7",
   "metadata": {},
   "source": [
    "To run inference on a new video:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your video file\n",
    "video_path = Path.home() / \"videos\" / \"example_video.mp4\"\n",
    "\n",
    "# Run inference\n",
    "if video_path.exists():\n",
    "    output_path = Model().run_inference(\n",
    "        model_key,\n",
    "        video_path=str(video_path),\n",
    "        save_as_csv=True,  # Also save as CSV for inspection\n",
    "        device=\"cuda\",  # Use GPU if available, otherwise \"cpu\"\n",
    "    )\n",
    "\n",
    "    print(f\"Inference complete: {output_path}\")\n",
    "\n",
    "    # Load the results into NWB\n",
    "    nwb_file = PoseEstim.load_dlc_output(\n",
    "        dlc_output_path=output_path, nwb_file_name=\"analysis_20250106.nwb\"\n",
    "    )\n",
    "\n",
    "    print(f\"Loaded into NWB: {nwb_file}\")\n",
    "else:\n",
    "    print(f\"Video not found: {video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4acc32b",
   "metadata": {},
   "source": [
    "#### Fetching Pose Estimation Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329642d2",
   "metadata": {},
   "source": [
    "After running inference, we can fetch the raw pose data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab55e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the PoseEstim entry\n",
    "pose_estim_key = {**model_key, \"analysis_file_name\": \"analysis_20250106.nwb\"}\n",
    "\n",
    "# Fetch as DataFrame\n",
    "pose_df = (PoseEstim() & pose_estim_key).fetch1_dataframe()\n",
    "\n",
    "# The DataFrame has MultiIndex columns: [scorer, bodypart, coords]\n",
    "print(pose_df.head())\n",
    "\n",
    "# Plot raw detections\n",
    "bodypart = \"nose\"  # Choose a bodypart from your model\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    pose_df[(\"scorer\", bodypart, \"x\")],\n",
    "    pose_df[(\"scorer\", bodypart, \"y\")],\n",
    "    c=pose_df[(\"scorer\", bodypart, \"likelihood\")],\n",
    "    cmap=\"viridis\",\n",
    "    s=1,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.xlabel(\"X position (pixels)\")\n",
    "plt.ylabel(\"Y position (pixels)\")\n",
    "plt.title(f\"{bodypart} raw detections\")\n",
    "plt.colorbar(label=\"Likelihood\")\n",
    "plt.gca().invert_yaxis()  # Image coordinates: (0,0) is top-left\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0685ef",
   "metadata": {},
   "source": [
    "### [PoseParams](#TableOfContents) <a id=\"PoseParams\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fe053",
   "metadata": {},
   "source": [
    "Before processing pose data, we need to define processing parameters.\n",
    "PoseParams stores configuration for:\n",
    "\n",
    "- **Orientation**: How to calculate head direction\n",
    "- **Centroid**: How to combine bodyparts into a single position\n",
    "- **Smoothing**: How to interpolate and smooth the trajectory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b8a443",
   "metadata": {},
   "source": [
    "#### View Available Parameter Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PoseParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c54a50",
   "metadata": {},
   "source": [
    "#### Use Default Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd67f8d6",
   "metadata": {},
   "source": [
    "For 2-LED tracking (common Frank Lab setup):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418dd59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PoseParams.insert_default(skip_duplicates=True)\n",
    "params_key = {\"pose_params\": \"default\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ab8a5",
   "metadata": {},
   "source": [
    "For 4-LED tracking:\n",
    "\n",
    "```python\n",
    "PoseParams.insert_4LED_default(skip_duplicates=True)\n",
    "params_key = {\"pose_params\": \"4LED_default\"}\n",
    "```\n",
    "\n",
    "For single marker tracking:\n",
    "\n",
    "```python\n",
    "PoseParams.insert_single_LED(skip_duplicates=True)\n",
    "params_key = {\"pose_params\": \"single_LED\"}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c6b060",
   "metadata": {},
   "source": [
    "#### Create Custom Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2cf3d9",
   "metadata": {},
   "source": [
    "For custom tracking scenarios:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PoseParams.insert_custom(\n",
    "    params_name=\"tutorial_custom\",\n",
    "    orient={\n",
    "        \"method\": \"two_pt\",  # Use two points to define orientation\n",
    "        \"bodypart1\": \"nose\",\n",
    "        \"bodypart2\": \"tail_base\",\n",
    "        \"interpolate\": True,\n",
    "        \"smooth\": True,\n",
    "    },\n",
    "    centroid={\n",
    "        \"method\": \"1pt\",  # Use single point as centroid\n",
    "        \"points\": {\"point1\": \"nose\"},\n",
    "    },\n",
    "    smoothing={\n",
    "        \"interpolate\": True,\n",
    "        \"interp_params\": {\n",
    "            \"max_pts_to_interp\": 10,\n",
    "            \"max_cm_to_interp\": 15.0,\n",
    "        },\n",
    "        \"smooth\": True,\n",
    "        \"smoothing_params\": {\n",
    "            \"method\": \"moving_avg\",\n",
    "            \"smoothing_duration\": 0.3,  # 300ms window\n",
    "        },\n",
    "        \"likelihood_thresh\": 0.95,\n",
    "    },\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f3ff8d",
   "metadata": {},
   "source": [
    "Inspect the parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d20523",
   "metadata": {},
   "outputs": [],
   "source": [
    "(PoseParams() & {\"pose_params\": \"tutorial_custom\"}).fetch1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea0c5e",
   "metadata": {},
   "source": [
    "### [PoseV2](#TableOfContents) <a id=\"PoseV2\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c1132",
   "metadata": {},
   "source": [
    "Now we can process the pose estimation to get cleaned, smoothed position data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17422ad",
   "metadata": {},
   "source": [
    "#### Create Processing Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cfee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PoseEstim, PoseParams, and VidFileGroup\n",
    "pose_v2_key = {\n",
    "    **pose_estim_key,\n",
    "    **params_key,\n",
    "}\n",
    "\n",
    "# Insert into PoseV2Selection (if using selection table pattern)\n",
    "# Or directly populate PoseV2\n",
    "PoseV2().populate(pose_v2_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c478b2",
   "metadata": {},
   "source": [
    "The PoseV2.make() pipeline performs:\n",
    "\n",
    "1. **Likelihood filtering**: Remove low-confidence detections\n",
    "2. **Orientation calculation**: Compute head direction\n",
    "3. **Centroid calculation**: Combine bodyparts into position\n",
    "4. **Interpolation**: Fill gaps in tracking\n",
    "5. **Smoothing**: Remove jitter from trajectories\n",
    "6. **Velocity calculation**: Compute speed\n",
    "7. **NWB storage**: Save results in standardized format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd9194",
   "metadata": {},
   "source": [
    "#### Verify Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PoseV2() & pose_v2_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727bd68b",
   "metadata": {},
   "source": [
    "### [Fetching Data](#TableOfContents) <a id=\"FetchData\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b5f69",
   "metadata": {},
   "source": [
    "PoseV2 provides two methods for retrieving processed data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5ef413",
   "metadata": {},
   "source": [
    "#### Method 1: fetch1_dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b04577e",
   "metadata": {},
   "source": [
    "Get cleaned data as a pandas DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe746d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = (PoseV2() & pose_v2_key).fetch1_dataframe()\n",
    "\n",
    "print(processed_df.head())\n",
    "print(f\"\\nColumns: {list(processed_df.columns)}\")\n",
    "print(\n",
    "    f\"Time range: {processed_df.index[0]:.2f} - {processed_df.index[-1]:.2f} s\"\n",
    ")\n",
    "print(f\"Mean speed: {processed_df['velocity'].mean():.2f} cm/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea31bb",
   "metadata": {},
   "source": [
    "#### Method 2: fetch_obj()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401589d2",
   "metadata": {},
   "source": [
    "Get raw pynwb objects for advanced analysis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce33c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all objects\n",
    "objs = (PoseV2() & pose_v2_key).fetch_obj()\n",
    "\n",
    "# Or fetch specific objects\n",
    "orient_obj = (PoseV2() & pose_v2_key).fetch_obj(\"orient\")\n",
    "centroid_obj = (PoseV2() & pose_v2_key).fetch_obj([\"centroid\", \"velocity\"])\n",
    "\n",
    "print(f\"Available objects: {list(objs.keys())}\")\n",
    "print(f\"Centroid object: {objs['centroid']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4db8e5",
   "metadata": {},
   "source": [
    "### [Visualization](#TableOfContents) <a id=\"Visualization\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b7ee3",
   "metadata": {},
   "source": [
    "Let's visualize the processed position data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b964bff7",
   "metadata": {},
   "source": [
    "#### Trajectory Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346bd205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot trajectory colored by speed\n",
    "scatter = ax.scatter(\n",
    "    processed_df[\"position_x\"],\n",
    "    processed_df[\"position_y\"],\n",
    "    c=processed_df[\"velocity\"],\n",
    "    cmap=\"viridis\",\n",
    "    s=5,\n",
    "    alpha=0.6,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"X position (cm)\")\n",
    "ax.set_ylabel(\"Y position (cm)\")\n",
    "ax.set_title(\"Animal trajectory (colored by speed)\")\n",
    "ax.axis(\"equal\")\n",
    "ax.invert_yaxis()  # Match video coordinates\n",
    "plt.colorbar(scatter, label=\"Speed (cm/s)\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522369b",
   "metadata": {},
   "source": [
    "#### Time Series Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Position over time\n",
    "axes[0].plot(\n",
    "    processed_df.index, processed_df[\"position_x\"], label=\"X\", alpha=0.7\n",
    ")\n",
    "axes[0].plot(\n",
    "    processed_df.index, processed_df[\"position_y\"], label=\"Y\", alpha=0.7\n",
    ")\n",
    "axes[0].set_ylabel(\"Position (cm)\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Orientation over time\n",
    "axes[1].plot(processed_df.index, np.rad2deg(processed_df[\"orientation\"]))\n",
    "axes[1].set_ylabel(\"Orientation (degrees)\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Speed over time\n",
    "axes[2].plot(processed_df.index, processed_df[\"velocity\"])\n",
    "axes[2].set_ylabel(\"Speed (cm/s)\")\n",
    "axes[2].set_xlabel(\"Time (s)\")\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec91e6",
   "metadata": {},
   "source": [
    "#### Quiver Plot (Orientation Arrows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample for clarity\n",
    "step = len(processed_df) // 50\n",
    "subsampled = processed_df.iloc[::step]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Plot trajectory\n",
    "ax.plot(\n",
    "    processed_df[\"position_x\"],\n",
    "    processed_df[\"position_y\"],\n",
    "    \"gray\",\n",
    "    alpha=0.3,\n",
    "    linewidth=0.5,\n",
    ")\n",
    "\n",
    "# Add orientation arrows\n",
    "arrow_length = 10  # cm\n",
    "ax.quiver(\n",
    "    subsampled[\"position_x\"],\n",
    "    subsampled[\"position_y\"],\n",
    "    arrow_length * np.cos(subsampled[\"orientation\"]),\n",
    "    arrow_length * np.sin(subsampled[\"orientation\"]),\n",
    "    subsampled[\"velocity\"],\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.8,\n",
    "    scale=200,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"X position (cm)\")\n",
    "ax.set_ylabel(\"Y position (cm)\")\n",
    "ax.set_title(\"Trajectory with orientation (colored by speed)\")\n",
    "ax.axis(\"equal\")\n",
    "ax.invert_yaxis()\n",
    "plt.colorbar(label=\"Speed (cm/s)\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81663b1",
   "metadata": {},
   "source": [
    "### [V1 vs V2 Comparison](#TableOfContents) <a id=\"Comparison\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78fcefb",
   "metadata": {},
   "source": [
    "| Feature | V1 | V2 |\n",
    "|---------|----|----|\n",
    "| **Tables** | 10+ tables | 4 main tables |\n",
    "| **Tools** | DLC only | DLC, SLEAP, ndx-pose |\n",
    "| **Model Import** | Multi-step | Single method |\n",
    "| **Processing** | 6 separate tables | 1 PoseV2 table |\n",
    "| **Parameters** | 4 param tables | 1 PoseParams table |\n",
    "| **Storage** | Custom format | NWB via ndx-pose |\n",
    "| **Multi-camera** | Limited | Native support |\n",
    "| **Flexibility** | Fixed pipeline | Configurable workflows |\n",
    "\n",
    "**Migration Path**: V1 and V2 can coexist. Both write to `PositionOutput`,\n",
    "so downstream analyses work with either version.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ae622",
   "metadata": {},
   "source": [
    "## Path 2: Train New Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096e74b4",
   "metadata": {},
   "source": [
    "For completeness, here's how to train a new model with V2:\n",
    "\n",
    "```python\n",
    "# 1. Create skeleton\n",
    "skeleton_id = Skeleton().insert1({\n",
    "    \"skeleton_name\": \"my_tracking\",\n",
    "    \"bodyparts\": [\"nose\", \"tail_base\", \"left_ear\", \"right_ear\"],\n",
    "    \"edges\": [[0, 1], [0, 2], [0, 3]],  # nose connects to all\n",
    "})\n",
    "\n",
    "# 2. Define training parameters\n",
    "params_key = ModelParams().insert1({\n",
    "    \"tool\": \"DLC\",\n",
    "    \"params\": {\n",
    "        \"project_path\": \"/path/to/dlc/project\",\n",
    "        \"net_type\": \"resnet_50\",\n",
    "        \"maxiters\": 100000,\n",
    "        \"shuffle\": 1,\n",
    "    },\n",
    "    \"skeleton_id\": skeleton_id\n",
    "})\n",
    "\n",
    "# 3. Create video group\n",
    "vid_group_key = VidFileGroup().create_from_files([\n",
    "    \"/path/to/video1.mp4\",\n",
    "    \"/path/to/video2.mp4\",\n",
    "])\n",
    "\n",
    "# 4. Train model\n",
    "sel_key = {**params_key, **vid_group_key}\n",
    "ModelSelection().insert1(sel_key)\n",
    "Model().populate(sel_key)  # This runs training\n",
    "\n",
    "# 5. Evaluate model\n",
    "model_key = (Model() & sel_key).fetch1(\"KEY\")\n",
    "results = Model().evaluate(model_key, plotting=True)\n",
    "print(f\"Test error: {results['test_error']:.2f} pixels\")\n",
    "\n",
    "# 6. Plot training history\n",
    "Model().plot_training_history(model_key, save_path=\"training_curve.png\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7ee08",
   "metadata": {},
   "source": [
    "## Troubleshooting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ad683",
   "metadata": {},
   "source": [
    "### Common Issues\n",
    "\n",
    "**Import fails - \"Model not found\"**:\n",
    "- Ensure DLC project has completed training\n",
    "- Check that model snapshots exist in `dlc-models/` directory\n",
    "- Verify config.yaml path is correct\n",
    "\n",
    "**Inference fails - \"CUDA out of memory\"**:\n",
    "- Use `device=\"cpu\"` instead of `device=\"cuda\"`\n",
    "- Process videos in smaller batches\n",
    "- Reduce video resolution\n",
    "\n",
    "**Low likelihood values**:\n",
    "- Model may not generalize to your videos\n",
    "- Consider fine-tuning with a few labeled frames\n",
    "- Adjust `likelihood_thresh` in PoseParams\n",
    "\n",
    "**Jerky trajectories**:\n",
    "- Increase `smoothing_duration` in PoseParams\n",
    "- Try different smoothing methods (savgol, gaussian)\n",
    "- Check for tracking failures (NaN values)\n",
    "\n",
    "**Missing bodyparts in output**:\n",
    "- Verify bodyparts in PoseParams match those in model\n",
    "- Check BodyPart table has required entries\n",
    "- Review DLC output files for completeness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e9f65",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Linearization**: Convert 2D position to 1D track position (notebook 24)\n",
    "- **Decoding**: Use position for neural decoding (notebooks 41-42)\n",
    "- **Custom Analysis**: Work directly with fetched DataFrames\n",
    "\n",
    "For questions, see the [Spyglass documentation](https://lorenfranklab.github.io/spyglass/)\n",
    "or open an issue on [GitHub](https://github.com/LorenFrankLab/spyglass).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
