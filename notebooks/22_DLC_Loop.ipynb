{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a93a1550-8a67-4346-a4bf-e5a136f3d903",
   "metadata": {},
   "source": [
    "## Position- DeepLabCut from Scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd3267",
   "metadata": {},
   "source": [
    "### Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52aff0d",
   "metadata": {},
   "source": [
    "_Developer Note:_ if you may make a PR in the future, be sure to copy this\n",
    "notebook, and use the `gitignore` prefix `temp` to avoid future conflicts.\n",
    "\n",
    "This is one notebook in a multi-part series on Spyglass.\n",
    "\n",
    "- To set up your Spyglass environment and database, see\n",
    "  [the Setup notebook](./00_Setup.ipynb)\n",
    "- For additional info on DataJoint syntax, including table definitions and\n",
    "  inserts, see\n",
    "  [the Insert Data notebook](./01_Insert_Data.ipynb)\n",
    "\n",
    "This tutorial will extract position via DeepLabCut (DLC). It will walk through...\n",
    "\n",
    "- creating a DLC project\n",
    "- extracting and labeling frames\n",
    "- training your model\n",
    "- executing pose estimation on a novel behavioral video\n",
    "- processing the pose estimation output to extract a centroid and orientation\n",
    "- inserting the resulting information into the `PositionOutput` table\n",
    "\n",
    "**Note 2: Make sure you are running this within the spyglass-dlc Conda environment (instructions for install are in the environment_dlc.yml)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b531f7",
   "metadata": {},
   "source": [
    "Here is a schematic showing the tables used in this pipeline.\n",
    "\n",
    "![dlc_scratch.png|2000x900](./../notebook-images/dlc_scratch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c67d88c-c90e-467b-ae2e-672c49a12f95",
   "metadata": {},
   "source": [
    "### Table of Contents<a id='TableOfContents'></a>\n",
    "\n",
    "[`DLCProject`](#DLCProject1)<br>\n",
    "[`DLCModelTraining`](#DLCModelTraining1)<br>\n",
    "[`DLCModel`](#DLCModel1)<br>\n",
    "[`DLCPoseEstimation`](#DLCPoseEstimation1)<br>\n",
    "[`DLCSmoothInterp`](#DLCSmoothInterp1)<br>\n",
    "[`DLCCentroid`](#DLCCentroid1)<br>\n",
    "[`DLCOrientation`](#DLCOrientation1)<br>\n",
    "[`DLCPosV1`](#DLCPosV1-1)<br>\n",
    "[`DLCPosVideo`](#DLCPosVideo1)<br>\n",
    "[`PositionOutput`](#PositionOutput1)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a0a678",
   "metadata": {},
   "source": [
    "**You can click on any header to return to the Table of Contents**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b98c3d",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36026fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f567531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datajoint as dj\n",
    "\n",
    "import spyglass.common as sgc\n",
    "import spyglass.position.v1 as sgp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pynwb\n",
    "from spyglass.position import PositionOutput\n",
    "\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "dj.config.load(\"dj_local_conf.json\")  # load config for database connection info\n",
    "\n",
    "# ignore datajoint+jupyter async warnings\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ResourceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6221a3-17e5-45c0-aa40-2fd664b02219",
   "metadata": {},
   "source": [
    "#### [DLCProject](#TableOfContents) <a id=\"DLCProject1\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aed0e1-3af7-4499-bae8-96a64e81041e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Notes:</b><ul>\n",
    "    <li>\n",
    "        The cells within this <code>DLCProject</code> step need to be performed \n",
    "        in a local Jupyter notebook to allow for use of the frame labeling GUI.\n",
    "    </li>\n",
    "    <li>\n",
    "        Please do not add to the <code>BodyPart</code> table in the production \n",
    "        database unless necessary.\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c9f1c9",
   "metadata": {},
   "source": [
    "### Body Parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307d3d7",
   "metadata": {},
   "source": [
    "### Body Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96637cb9-519d-41e1-8bfd-69f68dc66b36",
   "metadata": {},
   "source": [
    "We'll begin by looking at the `BodyPart` table, which stores standard names of body parts used in DLC models throughout the lab with a concise description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f829f-9877-48ae-89d1-f876af2b8835",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.BodyPart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616512e",
   "metadata": {},
   "source": [
    "If the bodyparts you plan to use in your model are not yet in the table, here is code to add bodyparts:\n",
    "\n",
    "```python\n",
    "sgp.BodyPart.insert(\n",
    "    [\n",
    "        {\"bodypart\": \"bp_1\", \"bodypart_description\": \"concise descrip\"},\n",
    "        {\"bodypart\": \"bp_2\", \"bodypart_description\": \"concise descrip\"},\n",
    "    ],\n",
    "    skip_duplicates=True,\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b590d3",
   "metadata": {},
   "source": [
    "### Define videos and camera name (optional) for training set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5aae37",
   "metadata": {},
   "source": [
    "To train a model, we'll need to extract frames, which we can label as training data. We can construct a list of videos from which we'll extract frames.\n",
    "\n",
    "The list can either contain dictionaries identifying behavioral videos for NWB files that have already been added to Spyglass, or absolute file paths to the videos (in .h264 format) you want to use.\n",
    "\n",
    "For this tutorial, we'll use two videos for which we already have frames labeled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e157b",
   "metadata": {},
   "source": [
    "Defining camera name is optional: it should be done in cases where there are multiple cameras streaming per epoch, but not necessary otherwise. <br>\n",
    "example:\n",
    "`camera_name = \"HomeBox_camera\" \n",
    "   `\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f45e7f",
   "metadata": {},
   "source": [
    "_NOTE:_ The official release of Spyglass does not yet support multicamera\n",
    "projects. You can monitor progress on the effort to add this feature by checking\n",
    "[this PR](https://github.com/LorenFrankLab/spyglass/pull/684) or use\n",
    "[this experimental branch](https://github.com/dpeg22/spyglass/tree/add-multi-camera),\n",
    "which takes the keys nwb_file_name and epoch, and camera_name in the video_list variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15971506",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = [\n",
    "    {\"nwb_file_name\": \"J1620210529_.nwb\", \"epoch\": 2},\n",
    "    {\"nwb_file_name\": \"peanut20201103_.nwb\", \"epoch\": 4},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8e43d",
   "metadata": {},
   "source": [
    "### Path variables\n",
    "\n",
    "The position pipeline also keeps track of paths for project, video, and output.\n",
    "Just like we saw in [Setup](./00_Setup.ipynb), you can manage these either with\n",
    "environmental variables...\n",
    "\n",
    "```bash\n",
    "export DLC_PROJECT_DIR=\"/nimbus/deeplabcut/projects\"\n",
    "export DLC_VIDEO_DIR=\"/nimbus/deeplabcut/video\"\n",
    "export DLC_OUTPUT_DIR=\"/nimbus/deeplabcut/output\"\n",
    "```\n",
    "\n",
    "<!-- NOTE: HDF5_USE_FILE_LOCKING now automatically set to 'FALSE' -->\n",
    "\n",
    "Or these can be set in your datajoint config:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"custom\": {\n",
    "    \"dlc_dirs\": {\n",
    "      \"base\": \"/nimbus/deeplabcut/\",\n",
    "      \"project\": \"/nimbus/deeplabcut/projects\",\n",
    "      \"video\": \"/nimbus/deeplabcut/video\",\n",
    "      \"output\": \"/nimbus/deeplabcut/output\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "_NOTE:_ If only `base` is specified as shown above, spyglass will assume the\n",
    "relative directories shown.\n",
    "\n",
    "You can check the result of this setup process with...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spyglass.settings import config\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c023b0-d00d-40b0-9a37-d0d3e4a4ae2a",
   "metadata": {},
   "source": [
    "Before creating our project, we need to define a few variables.\n",
    "\n",
    "- A team name, as shown in `LabTeam` for setting permissions. Here, we'll\n",
    "  use \"LorenLab\".\n",
    "- A `project_name`, as a unique identifier for this DLC project. Here, we'll use\n",
    "  **\"tutorial_scratch_yourinitials\"**\n",
    "- `bodyparts` is a list of body parts for which we want to extract position.\n",
    "  The pre-labeled frames we're using include the bodyparts listed below.\n",
    "- Number of frames to extract/label as `frames_per_video`. Note that the DLC creators recommend having 200 frames as the minimum total number for each project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = sgc.LabTeam.fetch(\"team_name\")[0]  # If on lab DB, \"LorenLab\"\n",
    "project_name = \"tutorial_scratch_DG\"\n",
    "frames_per_video = 100\n",
    "bodyparts = [\"redLED_C\", \"greenLED\", \"redLED_L\", \"redLED_R\", \"tailBase\"]\n",
    "project_key = sgp.DLCProject.insert_new_project(\n",
    "    project_name=project_name,\n",
    "    bodyparts=bodyparts,\n",
    "    lab_team=team_name,\n",
    "    frames_per_video=frames_per_video,\n",
    "    video_list=video_list,\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d83452-48eb-4669-89eb-a6beb1f2d051",
   "metadata": {},
   "source": [
    "Now that we've initialized our project we'll need to extract frames which we will then label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment this line out after you finish frame extraction for each project\n",
    "sgp.DLCProject().run_extract_frames(project_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68110734",
   "metadata": {},
   "source": [
    "This is the line used to label the frames you extracted, if you wish to use the DLC GUI on the computer you are currently using.\n",
    "\n",
    "```#comment this line out after frames are labeled for your project\n",
    "sgp.DLCProject().run_label_frames(project_key)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b241030",
   "metadata": {},
   "source": [
    "Otherwise, it is best/easiest practice to label the frames on your local computer (like a MacBook) that can run DeepLabCut's GUI well. Instructions: <br>\n",
    "\n",
    "1. Install DLC on your local (preferably into a 'Src' folder): https://deeplabcut.github.io/DeepLabCut/docs/installation.html\n",
    "2. Upload frames extracted and saved in nimbus (should be `/nimbus/deeplabcut/<YOUR_PROJECT_NAME>/labeled-data`) AND the project's associated config file (should be `/nimbus/deeplabcut/<YOUR_PROJECT_NAME>/config.yaml`) to Box (we get free with UCSF)\n",
    "3. Download labeled-data and config files on your local from Box\n",
    "4. Create a 'projects' folder where you installed DeepLabCut; create a new folder with your complete project name there; save the downloaded files there.\n",
    "5. Edit the config.yaml file: line 9 defining `project_path` needs to be the file path where it is saved on your local (ex: `/Users/lorenlab/Src/DeepLabCut/projects/tutorial_sratch_DG-LorenLab-2023-08-16`)\n",
    "6. Open the DLC GUI through terminal\n",
    "   <br>(ex: `conda activate miniconda/envs/DEEPLABCUT_M1`\n",
    "   <br>`pythonw -m deeplabcut`)\n",
    "7. Load an existing project; choose the config.yaml file\n",
    "8. Label frames; labeling tutorial: https://www.youtube.com/watch?v=hsA9IB5r73E.\n",
    "9. Once all frames are labeled, you should re-upload labeled-data folder back to Box and overwrite it in the original nimbus location so that your completed frames are ready to be used in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12dd229-2f8b-455a-a7b1-a20916cefed9",
   "metadata": {},
   "source": [
    "Now we can check the `DLCProject.File` part table and see all of our training files and videos there!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f3fa6-cce9-4d4a-a252-3424313c6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCProject.File & project_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e3eab-60c7-4a3c-bc8f-fd4e8dcf52a2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    This step and beyond should be run on a GPU-enabled machine.</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e48ecf0",
   "metadata": {},
   "source": [
    "#### [DLCModelTraining](#ToC)<a id='DLCModelTraining1'></a>\n",
    "\n",
    "Please make sure you're running this notebook on a GPU-enabled machine.\n",
    "\n",
    "Now that we've imported existing frames, we can get ready to train our model.\n",
    "\n",
    "First, we'll need to define a set of parameters for `DLCModelTrainingParams`, which will get used by DeepLabCut during training. Let's start with `gputouse`,\n",
    "which determines which GPU core to use.\n",
    "\n",
    "The cell below determines which core has space and set the `gputouse` variable\n",
    "accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.dlc_utils.get_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca035a9",
   "metadata": {},
   "source": [
    "Set GPU core:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "gputouse = 1  # 1-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b047686",
   "metadata": {},
   "source": [
    "Now we'll define the rest of our parameters and insert the entry.\n",
    "\n",
    "To see all possible parameters, try:\n",
    "\n",
    "```python\n",
    "sgp.DLCModelTrainingParams.get_accepted_params()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399581ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params_name = \"tutorial\"\n",
    "sgp.DLCModelTrainingParams.insert_new_params(\n",
    "    paramset_name=training_params_name,\n",
    "    params={\n",
    "        \"trainingsetindex\": 0,\n",
    "        \"shuffle\": 1,\n",
    "        \"gputouse\": gputouse,\n",
    "        \"net_type\": \"resnet_50\",\n",
    "        \"augmenter_type\": \"imgaug\",\n",
    "    },\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6cc709",
   "metadata": {},
   "source": [
    "Next we'll modify the `project_key` from above to include the necessary entries for `DLCModelTraining`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_key['project_path'] = os.path.dirname(project_key['config_path'])\n",
    "if \"config_path\" in project_key:\n",
    "    del project_key[\"config_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7ddaa",
   "metadata": {},
   "source": [
    "We can insert an entry into `DLCModelTrainingSelection` and populate `DLCModelTraining`.\n",
    "\n",
    "_Note:_ You can stop training at any point using `I + I` or interrupt the Kernel.\n",
    "\n",
    "The maximum total number of training iterations is 1030000; you can end training before this amount if the loss rate (lr) and total loss plateau and are very close to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c252541",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelTrainingSelection.heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d2f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sgp.DLCModelTrainingSelection().insert1(\n",
    "    {\n",
    "        **project_key,\n",
    "        \"dlc_training_params_name\": training_params_name,\n",
    "        \"training_id\": 0,\n",
    "        \"model_prefix\": \"\",\n",
    "    }\n",
    ")\n",
    "model_training_key = (\n",
    "    sgp.DLCModelTrainingSelection\n",
    "    & {\n",
    "        **project_key,\n",
    "        \"dlc_training_params_name\": training_params_name,\n",
    "    }\n",
    ").fetch1(\"KEY\")\n",
    "sgp.DLCModelTraining.populate(model_training_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da004b3e",
   "metadata": {},
   "source": [
    "Here we'll make sure that the entry made it into the table properly!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5306fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgp.DLCModelTraining() & model_training_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b7687",
   "metadata": {},
   "source": [
    "Populating `DLCModelTraining` automatically inserts the entry into\n",
    "`DLCModelSource`, which is used to select between models trained using Spyglass\n",
    "vs. other tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelSource() & model_training_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb8969",
   "metadata": {},
   "source": [
    "The `source` field will only accept _\"FromImport\"_ or _\"FromUpstream\"_ as entries. Let's checkout the `FromUpstream` part table attached to `DLCModelSource` below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc1afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelSource.FromUpstream() & model_training_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9b2c6",
   "metadata": {},
   "source": [
    "#### [DLCModel](#TableOfContents) <a id='DLCModel1'></a>\n",
    "\n",
    "Next we'll populate the `DLCModel` table, which holds all the relevant\n",
    "information for all trained models.\n",
    "\n",
    "First, we'll need to determine a set of parameters for our model to select the\n",
    "correct model file. Here is the default:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb663861",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelParams.get_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b45a6ed",
   "metadata": {},
   "source": [
    "Here is the syntax to add your own parameter set:\n",
    "\n",
    "```python\n",
    "dlc_model_params_name = \"make_this_yours\"\n",
    "params = {\n",
    "    \"params\": {},\n",
    "    \"shuffle\": 1,\n",
    "    \"trainingsetindex\": 0,\n",
    "    \"model_prefix\": \"\",\n",
    "}\n",
    "sgp.DLCModelParams.insert1(\n",
    "    {\"dlc_model_params_name\": dlc_model_params_name, \"params\": params},\n",
    "    skip_duplicates=True,\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bce9696",
   "metadata": {},
   "source": [
    "We can insert sets of parameters into `DLCModelSelection` and populate\n",
    "`DLCModel`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa23fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model_key = (sgp.DLCModelSource & model_training_key).fetch1(\"KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e418eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment these lines out after successfully inserting, for each project\n",
    "sgp.DLCModelSelection().insert1(\n",
    "    {**temp_model_key, \"dlc_model_params_name\": \"default\"}, skip_duplicates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae03bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key = (sgp.DLCModelSelection & temp_model_key).fetch1(\"KEY\")\n",
    "sgp.DLCModel.populate(model_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f1b839",
   "metadata": {},
   "source": [
    "Again, let's make sure that everything looks correct in `DLCModel`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModel() & model_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02202650",
   "metadata": {},
   "source": [
    "## Loop Begins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd886971",
   "metadata": {},
   "source": [
    "We can view all `VideoFile` entries with the specidied `camera_name` for this project to ensure the rat whose position you wish to model is in this table `matching_rows`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844174d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_name = \"SleepBox_camera\"\n",
    "matching_rows = sgc.VideoFile() & {\"camera_name\": camera_name}\n",
    "matching_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510cf05b",
   "metadata": {},
   "source": [
    "If the first insertion step (for pose estimation task) fails in either trigger or load mode for an epoch, run the following lines:\n",
    "\n",
    "```\n",
    "(pose_estimation_key = dlc_pose_estimation.insert_estimation_task(\n",
    "    key,\n",
    "    task_mode=\"trigger\", #trigger or load\n",
    "    params={\"gputouse\": gputouse, \"videotype\": \"mp4\"},\n",
    "    )).delete()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb99b6f",
   "metadata": {},
   "source": [
    "This loop will generate posiiton data for all epochs associated with the pre-defined camera in one day, for one rat (based on the NWB file; see \\*\\*\\*)\n",
    "<br>The output should print Pose Estimation and Centroid plots for each epoch.\n",
    "\n",
    "- It defines `col1val` as each `nwb_file_name` entry in the table, one at a time.\n",
    "- Next, it sees if the trial on which you are testing this model is in the string for the current `col1val`; if not, it re-defines `col1val` as the next `nwb_file_name` entry and re-tries this step.\n",
    "- If the previous step works, it then saves `col2val` and `col3val` as the `epoch` and the `video_file_num`, respectively, based on the nwb_file_name. From there, it iterates through the insertion and population steps required to extract position data, which we see laid out in the non-Loop DLC notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in matching_rows:\n",
    "    col1val = row[\"nwb_file_name\"]\n",
    "    if \"SC3820230606\" in col1val:  # *** change depending on rat/day!!!\n",
    "        col2val = row[\"epoch\"]\n",
    "        col3val = row[\"video_file_num\"]\n",
    "\n",
    "        ##insert pose estimation task\n",
    "        key = {\"nwb_file_name\": nwb_file_name,\n",
    "               \"epoch\": epoch,\n",
    "               \"video_file_num\": video_file_num,\n",
    "               **model_key,\n",
    "               }\n",
    "        \n",
    "        dlc_pose_estimation = sgp.DLCPoseEstimationSelection()  # Create an instance\n",
    "\n",
    "        pose_estimation_key = dlc_pose_estimation.insert_estimation_task(\n",
    "            key,\n",
    "            task_mode=\"trigger\", #trigger or load\n",
    "            params={\"gputouse\": gputouse, \"videotype\": \"mp4\"},\n",
    "            )\n",
    "\n",
    "        ##populate DLC Pose Estimation\n",
    "        sgp.DLCPoseEstimation().populate(pose_estimation_key)\n",
    "\n",
    "        ##start smooth interpolation\n",
    "        si_params_name = \"just_nan\"\n",
    "        si_key = pose_estimation_key.copy()\n",
    "        fields = list(sgp.DLCSmoothInterpSelection.fetch().dtype.fields.keys())\n",
    "        si_key = {key: val for key, val in si_key.items() if key in fields}\n",
    "        bodyparts = [\"greenLED\", \"redLED_C\"]\n",
    "        sgp.DLCSmoothInterpSelection.insert(\n",
    "            [\n",
    "                {\n",
    "                    **si_key,\n",
    "                    \"bodypart\": bodypart,\n",
    "                    \"dlc_si_params_name\": si_params_name,\n",
    "                }\n",
    "                for bodypart in bodyparts\n",
    "            ],\n",
    "            skip_duplicates=True,\n",
    "        )\n",
    "        sgp.DLCSmoothInterp().populate(si_key)\n",
    "        (\n",
    "            sgp.DLCSmoothInterp() & {**si_key, \"bodypart\": bodyparts[0]}\n",
    "        ).fetch1_dataframe().plot.scatter(x=\"x\", y=\"y\", s=1, figsize=(5, 5))\n",
    "\n",
    "        ##smoothinterpcohort\n",
    "        cohort_key = si_key.copy()\n",
    "        if \"bodypart\" in cohort_key:\n",
    "            del cohort_key[\"bodypart\"]\n",
    "        if \"dlc_si_params_name\" in cohort_key:\n",
    "            del cohort_key[\"dlc_si_params_name\"]\n",
    "        cohort_key[\"dlc_si_cohort_selection_name\"] = \"green_red_led\"\n",
    "        cohort_key[\"bodyparts_params_dict\"] = {\n",
    "            \"greenLED\": si_params_name,\n",
    "            \"redLED_C\": si_params_name,\n",
    "        }\n",
    "        sgp.DLCSmoothInterpCohortSelection().insert1(\n",
    "            cohort_key, skip_duplicates=True\n",
    "        )\n",
    "        sgp.DLCSmoothInterpCohort.populate(cohort_key)\n",
    "\n",
    "        ##DLC Centroid\n",
    "        centroid_params_name = \"default\"\n",
    "        centroid_key = cohort_key.copy()\n",
    "        fields = list(sgp.DLCCentroidSelection.fetch().dtype.fields.keys())\n",
    "        centroid_key = {\n",
    "            key: val for key, val in centroid_key.items() if key in fields\n",
    "        }\n",
    "        centroid_key[\"dlc_centroid_params_name\"] = centroid_params_name\n",
    "        sgp.DLCCentroidSelection.insert1(centroid_key, skip_duplicates=True)\n",
    "        sgp.DLCCentroid.populate(centroid_key)\n",
    "        (sgp.DLCCentroid() & centroid_key).fetch1_dataframe().plot.scatter(\n",
    "            x=\"position_x\",\n",
    "            y=\"position_y\",\n",
    "            c=\"speed\",\n",
    "            colormap=\"viridis\",\n",
    "            alpha=0.5,\n",
    "            s=0.5,\n",
    "            figsize=(10, 10),\n",
    "        )\n",
    "\n",
    "        ##DLC Orientation\n",
    "        dlc_orientation_params_name = \"default\"\n",
    "        fields = list(sgp.DLCOrientationSelection.fetch().dtype.fields.keys())\n",
    "        orient_key = {\n",
    "            key: val for key, val in cohort_key.items() if key in fields\n",
    "        }\n",
    "        orient_key[\"dlc_orientation_params_name\"] = dlc_orientation_params_name\n",
    "        sgp.DLCOrientationSelection().insert1(orient_key, skip_duplicates=True)\n",
    "        sgp.DLCOrientation().populate(orient_key)\n",
    "\n",
    "        ##DLCPosV1\n",
    "        fields = list(sgp.DLCPosV1.fetch().dtype.fields.keys())\n",
    "        dlc_key = {\n",
    "            key: val for key, val in centroid_key.items() if key in fields\n",
    "        }\n",
    "        dlc_key[\"dlc_si_cohort_centroid\"] = centroid_key[\n",
    "            \"dlc_si_cohort_selection_name\"\n",
    "        ]\n",
    "        dlc_key[\"dlc_si_cohort_orientation\"] = orient_key[\n",
    "            \"dlc_si_cohort_selection_name\"\n",
    "        ]\n",
    "        dlc_key[\"dlc_orientation_params_name\"] = orient_key[\n",
    "            \"dlc_orientation_params_name\"\n",
    "        ]\n",
    "        sgp.DLCPosSelection().insert1(dlc_key, skip_duplicates=True)\n",
    "        sgp.DLCPosV1().populate(dlc_key)\n",
    "\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be097052-3789-4d55-aca1-e44d426c39b4",
   "metadata": {},
   "source": [
    "### _CONGRATULATIONS!!_\n",
    "\n",
    "Please treat yourself to a nice tea break :-)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c90a2",
   "metadata": {},
   "source": [
    "### [Return To Table of Contents](#TableOfContents)<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
