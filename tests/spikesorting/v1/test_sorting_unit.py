"""Unit tests for SpikeSorting with mocked external operations.

These tests use monkeypatch to replace expensive external operations (spikeinterface sorting)
with instant mock functions, allowing fast validation of Spyglass logic without waiting
for slow spike sorting algorithms.

Runtime: ~2-3s (vs ~95s for integration tests)
"""

import pytest


def test_spike_sorting_logic_mocked(
    spike_v1,
    monkeypatch,
    mock_spike_sorter,
    mock_sorting_save,
    pop_rec,
    pop_art,
    mini_dict,
    sorter_dict,
):
    """Test Spyglass spike sorting logic with mocked external operations.

    This test validates:
    - SpikeSorting.populate() executes without errors
    - Table insertion succeeds with mocked data
    - All Spyglass code paths execute (fetch, params, intervals, database)
    - Result can be retrieved after population

    Mocked operations:
    - _run_spike_sorter() - Returns fake sorting object instantly
    - _save_sorting_results() - Returns fake analysis file name and object ID

    Runtime: ~2-3s (vs ~95s for real spike sorting)
    """
    # Apply mocks to SpikeSorting
    monkeypatch.setattr(
        spike_v1.SpikeSorting,
        "_run_spike_sorter",
        mock_spike_sorter,
    )
    monkeypatch.setattr(
        spike_v1.SpikeSorting,
        "_save_sorting_results",
        mock_sorting_save,
    )

    # Create selection key
    key = {
        **mini_dict,
        **sorter_dict,
        "recording_id": pop_rec["recording_id"],
        "interval_list_name": str(pop_art["artifact_id"]),
        "sorter_param_name": "franklab_tetrode_hippocampus_30KHz",
    }

    # Insert selection
    spike_v1.SpikeSortingSelection.insert_selection(key)

    # Run populate - tests ALL Spyglass logic
    spike_v1.SpikeSorting.populate()

    # Verify results exist
    sorting_table = spike_v1.SpikeSorting()
    assert sorting_table, "SpikeSorting should have entries after populate"

    # Verify we can fetch results
    results = sorting_table.fetch(as_dict=True)
    assert results is not None, "Should be able to fetch results"
    assert len(results) > 0, "Should have at least one result"

    # Verify key fields exist
    first_result = results[0]
    expected_keys = [
        "sorting_id",
        "analysis_file_name",
        "object_id",
    ]

    for key_field in expected_keys:
        assert key_field in first_result, f"Result should contain {key_field}"

    # Verify object_id exists (actual value may be generated by AnalysisNwbfile)
    assert first_result["object_id"], "Should have an object_id"
    assert isinstance(
        first_result["object_id"], str
    ), "object_id should be a string"

    print(f"âœ… Mocked spike sorting test passed ({len(sorting_table)} entries)")
